# 问题提出
    一般正负样本相差一个数量级以上称为数据不平衡问题
# 基于数据的解决方案
## 上采样
    方法： 将数据量小的样本复制多份
    存在的问题： 数据集中出现很多重复样本
    解决方法： 
      1. 在生成新数据时，随机加入一些噪声
      2. SMOTE算法： 在样本量小的类中的每个样本x，从小类集合中随机选择一个它的k近邻样本y, 从x, y连线上选择一点作为新样本（根据采样倍率，重复若干次）
## 下采样
    方法： 从数量多的样本中选择一个子集
    存在的问题： 最终的模型只学到了原始数据的一部分
    解决方法：
      1. 简单集成： 在随即采样多次，每次训练一个模型，最终结果由多个模型决定，其中一个样本始终不被选中的概率为 1/e=0.368。
      2. boost思想： 每次从多数类中采样，训练模型，下次再采样时，剔除一部分被当前分类器准确分类的样本，最后融合
## 基于算法的解决方案
## 修改目标函数
  方法： 代价敏感的学习中，不同类别有不同的权重
## 数量极其不平衡时
  方法： 将问题变为异常检测
      
