# 循环神经网络的梯度消失
    雅可比矩阵：前一层对后一层求导
    梯度传递为连层形式
    如果最大特征值大于1：梯度爆炸
    如果最大特征值小于1：梯度消失
    梯度爆炸解决办法：梯度裁剪
    梯度消失办法：LSTM，GRU
    ReLU在RNN中容易出现梯度消失爆炸的问题
    LSTM激活函数：
      遗忘门，输入门，输出门，sigmoid
      生成候选记忆时：使用Tanh
